{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9df2b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19516\\1154704787.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0moutput_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0msave_resized_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19516\\1154704787.py\u001b[0m in \u001b[0;36msave_resized_image\u001b[1;34m(input_path, output_path, new_shape)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mresized_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresize_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mresized_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNifti1Image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresized_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mnib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresized_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ATR_data/data'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nibabel\\loadsave.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(img, filename, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;31m# Save the type as expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_filename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImageFileError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nibabel\\filebasedimages.py\u001b[0m in \u001b[0;36mto_filename\u001b[1;34m(self, filename, **kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \"\"\"\n\u001b[0;32m    301\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilespec_to_file_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_file_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_file_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_map\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFileMap\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nibabel\\nifti1.py\u001b[0m in \u001b[0;36mto_file_map\u001b[1;34m(self, file_map, dtype)\u001b[0m\n\u001b[0;32m   2217\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2218\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2219\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_file_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2220\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2221\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nibabel\\analyze.py\u001b[0m in \u001b[0;36mto_file_map\u001b[1;34m(self, file_map, dtype)\u001b[0m\n\u001b[0;32m   1051\u001b[0m         \u001b[1;31m# Write array data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m         \u001b[0marr_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_fileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1053\u001b[1;33m         \u001b[0mhdrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_if_mine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1054\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhdr_img_same\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[0mimgf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_if_mine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nibabel\\openers.py\u001b[0m in \u001b[0;36mclose_if_mine\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;34m\"\"\"Close ``self.fobj`` iff we opened it in the constructor\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mme_opened\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nibabel\\openers.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mWRITE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m                 \u001b[0mfileobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m                 \u001b[0mwrite32u\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m                 \u001b[1;31m# self.size may exceed 2 GiB, or even 4 GiB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import nibabel as nib\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "def load_nifti_image(file_path):\n",
    "    return nib.load(file_path)\n",
    "\n",
    "def resize_image(image_data, new_shape):\n",
    "    factors = [new_shape[i] / image_data.shape[i] for i in range(3)]\n",
    "    return zoom(image_data, factors, order=1)\n",
    "\n",
    "def save_resized_image(input_path, output_path, new_shape):\n",
    "    image = load_nifti_image(input_path)\n",
    "    image_data = image.get_fdata()\n",
    "    resized_data = resize_image(image_data, new_shape)\n",
    "    resized_image = nib.Nifti1Image(resized_data, image.affine)\n",
    "    nib.save(resized_image, output_path)\n",
    "\n",
    "data_dir = 'ATR_data/data'\n",
    "output_dir = 'ATR_final'\n",
    "new_shape = (128, 128, 128)\n",
    "\n",
    "file_paths = glob.glob(os.path.join(data_dir, '*.nii.gz'))\n",
    "for file_path in file_paths:\n",
    "    filename = os.path.basename(file_path)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    save_resized_image(file_path, output_path, new_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6a747ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19516\\1257665392.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Load labels and features from Excel file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mlabels_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ATR_GT_training.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0msubject_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'subject_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3505\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3631\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3632\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3633\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn import svm\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load labels and features from Excel file\n",
    "labels_df = pd.read_excel('ATR_training.xlsx')\n",
    "labels = labels_df['label'].values\n",
    "subject_ids = labels_df['subject_id'].values\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_features(image):\n",
    "    return np.mean(image.get_fdata())\n",
    "\n",
    "# Load nii.gz images and extract features\n",
    "features = []\n",
    "for subject_id in subject_ids:\n",
    "    img_path = f'ATR_final/{subject_id}.nii.gz'\n",
    "    img = nib.load(img_path)\n",
    "    features.append(extract_features(img))\n",
    "\n",
    "features = np.array(features)\n",
    "\n",
    "# Data preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, 1))\n",
    "X_test = scaler.transform(X_test.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# SVM classification\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"The model is {accuracy*100}% accurate\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(classification_report(y_test, y_pred, target_names=['0', '1', '2' , '3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb266158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import ndimage as nd\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def extract_features(image_path, num_bins=100):\n",
    "    nii_image =nib.load(image_path)\n",
    "    \n",
    "    image_data = nii_image.get_fdata()\n",
    "    \n",
    "    flat_data = image_data.ravel()\n",
    "    \n",
    "    hist, _ = np.histogram(flat_data, bins=num_bins)\n",
    "    \n",
    "    histo_norm = hist / hist.sum()\n",
    "    \n",
    "    return histo_norm\n",
    "\n",
    "def extract_stat_features(image_path):\n",
    "    features = []\n",
    "    \n",
    "    nii_image =nib.load(image_path)\n",
    "    \n",
    "    image_data = nii_image.get_fdata()\n",
    "    \n",
    "    nonzero = image_data[np.nonzero(image_data)]\n",
    "    \n",
    "    mean = np.mean(non_zero)\n",
    "    \n",
    "    median = nd.median(zero_data)\n",
    "    \n",
    "    maximum = np.max(flat_data)\n",
    "    \n",
    "    std = nd.standard_deviation(flat_data)\n",
    "    \n",
    "    var = nd.variance(flat_data)\n",
    "    \n",
    "    skew = stats.skew(flat_data,axis=None)\n",
    "    \n",
    "    kurtosis = stats.kurtosis(flat_data,axis=None)\n",
    "    \n",
    "    features.append([mean,median,maximum,std,var,skew,kurtosis])\n",
    "    \n",
    "    return features\n",
    "    \n",
    "\n",
    "\n",
    "#define directorys\n",
    "\n",
    "input_dir = 'ATR_smoth'\n",
    "excel_file = 'ATR_training.xlsx'\n",
    "num_bins = 50\n",
    "\n",
    "#read labels\n",
    "labels_df = pd.read_excel(excel_file)\n",
    "labels = labels_df['label'].values\n",
    "\n",
    "# Extract histo features for all images\n",
    "\n",
    "feature_list = []\n",
    "file_list = sorted(os.listdir(input_dir))\n",
    "for filename in file_list:\n",
    "    if filename.endswith('.nii.gz'):\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        features = extract_features(input_path, num_bins)\n",
    "        stat_features = extract_stat_features(input_path)\n",
    "        feature_list.append(features)\n",
    "        total_features = features_list + stat_features\n",
    "        \n",
    "        \n",
    "#convert list to array\n",
    "X = np.array(total_features)\n",
    "\n",
    "#labels\n",
    "y = np.array(labels)\n",
    "\n",
    "#standarize the features \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#Cross Validation function for each classifier\n",
    "def cross_val(clf,X,y,clf_string, cv=5):\n",
    "    scores = cross_val_score(clf,X, y, cv=cv)\n",
    "    print('Clf: {}\\nAccuracy Mean: {:0.2f}\\nStandard Deviation{:0.2f}'.format(clf_string, scores.mean(), scores.std()))\n",
    "    \n",
    "#Testing on multiple models\n",
    "clfs = []\n",
    "svm = SVC(kernel='linear', C=5)\n",
    "clfs.append([svm,'Support Vector Machine'])\n",
    "lr = LogisticRegression(random_state = 0, solver = 'lbfgs',multi_class='multinomial')\n",
    "clfs.append([lr,'Logistic Regression'])\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "clfs.append([ada,'AdaBoost'])\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "clfs.append([knn,'K-Neighbors'])\n",
    "\n",
    "for clf, clf_str in clfs:\n",
    "    cross_val(clf,X_scaled,y,clf_str)\n",
    "\n",
    "#Returns overall Accuracy Score\n",
    "def overall_acc(y_true,y_pred):\n",
    "    return accuracy_score(y_true,y_pred)\n",
    "\n",
    "#Returns the percent detected(#targets detected and #targets)\n",
    "def PD(y_true,y_pred):\n",
    "    return recall_score(y_true,y_pred)\n",
    "\n",
    "#Returns the percent of false alarms(#false alarms and #non-targets)\n",
    "def PFA(y_true,y_pred):\n",
    "    return 1 - accuracy_score(1-y_true,1-y_pred)\n",
    "    \n",
    "def results(X,y,clf):\n",
    "    kf = KFold(n_splits=5)\n",
    "    per_det_0 = []\n",
    "    per_det_1 = []\n",
    "    per_det_2 = []\n",
    "    per_det_3 = []\n",
    "    per_false_alarm = []\n",
    "    acc = []\n",
    "    \n",
    "    for train_i, test_i in kf.split(X):\n",
    "        X_train, X_test = X[train_i],X[test_i]\n",
    "        y_train, y_test = y[train_i], y[test_i]\n",
    "        \n",
    "        predict = clf.fit(X_train, y_train != 0).predict(X_test)\n",
    "        \n",
    "        acc.append(overall_acc(y_test != 0, predict))\n",
    "        per_det_0.append(PD(y_test != 0),predict)\n",
    "        per_det_1.append(PD(y_test == 1),predict)\n",
    "        per_det_2.append(PD(y_test == 2),predict)\n",
    "        per_det_3.append(PD(y_test == 3),predict)\n",
    "        per_false_alarm.append(PFA(y_test != 0, predict))\n",
    "        \n",
    "    print('Accuracy: ', np.mean(acc))\n",
    "    print('Percent Detected: ', np.mean(per_det_0))\n",
    "    print('Percent False Alarm: ', np.mean(per_false_alarm))\n",
    "    print('Percent Saline Detected: ', np.mean(per_det_1))\n",
    "    print('Percent Rubber Detected: ', np.mean(per_det_2))\n",
    "    print('Percent Clay Detected: ', np.mean(per_det_3))\n",
    "\n",
    "for clf, clf_str in clfs:\n",
    "    cross_val(clf,X_scaled,y,clf_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f38faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30797c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def apply_gaussian_filter(input_dir,output_dir, sigma):\n",
    "    \n",
    "    nii_image = nib.load(input_dir)\n",
    "    \n",
    "    im_data = nii_image.get_fdata()\n",
    "    \n",
    "    smoth_data = gaussian_filter(im_data, sigma)\n",
    "    \n",
    "    smoth_data[smoth_data != 0] = 0\n",
    "    \n",
    "    mod_nii_image = nib.Nifti1Image(smoth_data, nii_image.affine)\n",
    "    \n",
    "    nib.save(mod_nii_image, output_dir)\n",
    "    \n",
    "\n",
    "#define var\n",
    "input_dir = 'ATR_data'\n",
    "output_dir = 'ATR_smoth'\n",
    "sigma = 10.65\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.nii.gz'):\n",
    "            input_path = os.path.join(input_dir, filename)\n",
    "            output_path = os.path.join(output_dir, f'smoth_{filename}')\n",
    "\n",
    "            apply_gaussian_filter(input_path, output_path , sigma)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
