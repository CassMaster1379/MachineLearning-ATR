{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ffcc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def apply_gaussian_filter(input_dir,output_dir, sigma):\n",
    "    \n",
    "    nii_image = nib.load(input_dir)\n",
    "    \n",
    "    im_data = nii_image.get_fdata()\n",
    "    \n",
    "    smoth_data = gaussian_filter(im_data, sigma)\n",
    "    \n",
    "    smoth_data[smoth_data != 0] = 0\n",
    "    \n",
    "    mod_nii_image = nib.Nifti1Image(smoth_data, nii_image.affine)\n",
    "    \n",
    "    nib.save(mod_nii_image, output_dir)\n",
    "    \n",
    "\n",
    "#define var\n",
    "input_dir = 'ATR_data'\n",
    "output_dir = 'ATR_smoth'\n",
    "sigma = 10.65\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.nii.gz'):\n",
    "            input_path = os.path.join(input_dir, filename)\n",
    "            output_path = os.path.join(output_dir, f'smoth_{filename}')\n",
    "\n",
    "            apply_gaussian_filter(input_path, output_path , sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "150b8df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cassa\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Cassa\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Cassa\\anaconda3\\lib\\site-packages\\scipy\\ndimage\\_measurements.py:502: RuntimeWarning: Mean of empty slice.\n",
      "  vals_c = vals - vals.mean()\n",
      "C:\\Users\\Cassa\\anaconda3\\lib\\site-packages\\scipy\\ndimage\\_measurements.py:736: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return sum_c_sq / np.asanyarray(count).astype(float)\n",
      "C:\\Users\\Cassa\\anaconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:1340: RuntimeWarning: Mean of empty slice.\n",
      "  mean = a.mean(axis, keepdims=True)\n",
      "C:\\Users\\Cassa\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n",
      "C:\\Users\\Cassa\\anaconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:1452: RuntimeWarning: Mean of empty slice.\n",
      "  mean = a.mean(axis, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import ndimage as nd\n",
    "from scipy import stats\n",
    "\n",
    "def extract_features(image_path, num_bins=100):\n",
    "    nii_image =nib.load(image_path)\n",
    "    \n",
    "    image_data = nii_image.get_fdata()\n",
    "    \n",
    "    flat_data = image_data.ravel()\n",
    "    \n",
    "    hist, _ = np.histogram(flat_data, bins=num_bins)\n",
    "    \n",
    "    histo_norm = hist / hist.sum()\n",
    "    \n",
    "    return histo_norm\n",
    "\n",
    "def extract_stat_features(image_path):\n",
    "    features = []\n",
    "    \n",
    "    nii_image =nib.load(image_path)\n",
    "    \n",
    "    image_data = nii_image.get_fdata()\n",
    "    \n",
    "    non_zero = image_data[np.nonzero(image_data)]\n",
    "    \n",
    "    mean = np.mean(non_zero)\n",
    "    \n",
    "    median = nd.median(non_zero)\n",
    "    \n",
    "    #maximum = np.max(non_zero)\n",
    "    \n",
    "    std = nd.standard_deviation(non_zero)\n",
    "    \n",
    "    var = nd.variance(non_zero)\n",
    "    \n",
    "    skew = stats.skew(non_zero,axis=None)\n",
    "    \n",
    "    kurtosis = stats.kurtosis(non_zero,axis=None)\n",
    "    \n",
    "    features.append([mean,median,std,var,skew,kurtosis])\n",
    "    \n",
    "    return features\n",
    "\n",
    "#define directorys\n",
    "\n",
    "input_dir = 'ATR_smoth'\n",
    "excel_file = 'ATR_training.xlsx'\n",
    "num_bins = 50\n",
    "\n",
    "#read labels\n",
    "labels_df = pd.read_excel(excel_file)\n",
    "labels = labels_df['label'].values\n",
    "\n",
    "# Extract histo features for all images\n",
    "\n",
    "hist_list = []\n",
    "stat_list = []\n",
    "file_list = sorted(os.listdir(input_dir))\n",
    "for filename in file_list:\n",
    "    if filename.endswith('.nii.gz'):\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        hist_features = extract_features(input_path, num_bins)\n",
    "        stat_features = extract_stat_features(input_path)\n",
    "        hist_list.append(hist_features)\n",
    "        stat_list.append(stat_features)\n",
    "        \n",
    "        \n",
    "np.save('features_stats.npy', np.array(stat_list))\n",
    "np.save('features_histogram.npy', np.array(hist_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f73567c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "feature_stats = np.load('stat_features.npy')\n",
    "feature_histogram = np.load('features_histogram.npy')\n",
    "features = np.concatenate((feature_stats,feature_histogram),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "632a84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import nibabel as nb\n",
    "from nilearn import plotting as plot\n",
    "from nilearn import image as img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import ndimage as nd\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.read_excel(\"ATR_GT_Training_og.xlsx\",header = None, names=['File Name','Label'])\n",
    "df['File Name'] = df['File Name'].map(lambda x: x.lstrip(\"'\").rstrip(\"'\"))\n",
    "df['Image'] = df['File Name'].map(lambda x: nb.load('ATR_data/' + str(x) + '.nii.gz'))\n",
    "#feature_labels = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d185c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate((feature_stats,feature_histogram),axis=1)\n",
    "\n",
    "X_train = features[:1005]\n",
    "y_train = df.Label[:1005]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0c36553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clf: Support Vector Machine\n",
      "Accuracy Mean: 0.74\n",
      "Standard Deviation: 0.01\n",
      "Clf: Logistic Regression\n",
      "Accuracy Mean: 0.72\n",
      "Standard Deviation: 0.02\n",
      "Clf: AdaBoost\n",
      "Accuracy Mean: 0.64\n",
      "Standard Deviation: 0.03\n",
      "Clf: K-Neighbors\n",
      "Accuracy Mean: 0.81\n",
      "Standard Deviation: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cassa\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Cassa\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Cassa\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Cassa\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Cassa\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "#standarize the features \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "#Cross Validation function for each classifier\n",
    "def cross_val(clf,X,y,clf_string, cv=5):\n",
    "    scores = cross_val_score(clf,X, y, cv=cv)\n",
    "    print('Clf: {}\\nAccuracy Mean: {:0.2f}\\nStandard Deviation: {:0.2f}'.format(clf_string, scores.mean(), scores.std()))\n",
    "\n",
    "\n",
    "#Testing on multiple models\n",
    "clfs = []\n",
    "#C = 5 is good optimization parameter to keep the misclassification rate lower and keep the hyperplane classifying point correcly\n",
    "svm = SVC(kernel='linear', C=5)\n",
    "clfs.append([svm,'Support Vector Machine'])\n",
    "lr = LogisticRegression(random_state = 0, solver = 'lbfgs',multi_class='multinomial')\n",
    "clfs.append([lr,'Logistic Regression'])\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "clfs.append([ada,'AdaBoost'])\n",
    "knn = KNeighborsClassifier(n_neighbors = 1, leaf_size = 1, p=1)\n",
    "clfs.append([knn,'K-Neighbors'])\n",
    "\n",
    "for clf, clf_str in clfs:\n",
    "    cross_val(clf,X_scaled,y_train,clf_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f874c4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5, kernel='linear')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1b2b412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cassa\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "#Predictions using the KNN classifier model\n",
    "X_test_truth = features[-467:, :]\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test_truth)\n",
    "\n",
    "np_df = df.to_numpy()\n",
    "np_test = np_df[-467:, :]\n",
    "\n",
    "df_test = pd.DataFrame(np_test, columns = ['file_name','label','image'])\n",
    "df_test['label'] = y_pred\n",
    "\n",
    "df_test.to_excel('predictions_new.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5699024b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 1. 0. 3. 0. 0. 0. 2. 0. 3. 0. 0. 0. 0. 3.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 2. 0. 3. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 2. 0. 0. 2. 0. 0. 0. 1. 3. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 0. 1. 3. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 3. 0. 3.\n",
      " 2. 0. 2. 0. 0. 3. 0. 2. 2. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 2. 3.\n",
      " 0. 0. 0. 2. 0. 1. 0. 0. 0. 0. 0. 0. 2. 1. 3. 0. 0. 2. 0. 3. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 2. 0. 1. 3. 2. 0. 1. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 2. 0. 3. 0. 0. 0. 0. 0. 1. 0. 3. 2. 0. 0. 0. 1. 0. 0. 3. 1. 0. 0.\n",
      " 0. 0. 3. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 2. 0. 0.\n",
      " 0. 3. 0. 0. 0. 2. 3. 0. 2. 0. 1. 0. 2. 0. 0. 0. 0. 3. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 3. 0. 0. 0. 0. 2. 0. 1. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 2. 0.\n",
      " 0. 3. 2. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 3. 1. 0. 0. 3. 2. 0. 2. 2. 1. 0. 1. 0. 0. 2. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 3. 0. 0. 0. 1. 2. 0. 3. 0. 0. 0. 0. 2. 0. 0. 2. 0. 0. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 1. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 2. 0.\n",
      " 0. 3. 0. 2. 0. 1. 3. 1. 0. 2. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
