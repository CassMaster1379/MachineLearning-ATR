{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019676af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def extract_features(image_path, num_bins=100):\n",
    "    nii_image =nib.load(image_path)\n",
    "    \n",
    "    image_data = nii_image.get_fdata()\n",
    "    \n",
    "    flat_data = image_data.ravel()\n",
    "    \n",
    "    hist, _ = np.histogram(flat_data, bins=num_bins)\n",
    "    \n",
    "    histo_norm = hist / hist.sum()\n",
    "    \n",
    "    return histo_norm\n",
    "\n",
    "def extract_stat_features(image_path):\n",
    "    features = []\n",
    "    \n",
    "    nii_image =nib.load(image_path)\n",
    "    \n",
    "    image_data = nii_image.get_fdata()\n",
    "    \n",
    "    flat_data = image_data.ravel()\n",
    "    \n",
    "    mean = np.mean(flat_data)\n",
    "    \n",
    "    median = nd.median(flat_data)\n",
    "    \n",
    "    maximum = np.max(flat_data)\n",
    "    \n",
    "    std = nd.standard_deviation(flat_data)\n",
    "    \n",
    "    var = nd.variance(flat_data)\n",
    "    \n",
    "    skew = stats.skew(flat_data,axis=None)\n",
    "    \n",
    "    kurtosis = stats.kurtosis(flat_data,axis=None)\n",
    "    \n",
    "    features.append([mean,median,maximum,std,var,skew,kurtosis])\n",
    "    \n",
    "    return features\n",
    "\n",
    "#define directorys\n",
    "\n",
    "input_dir = 'ATR_smoth'\n",
    "excel_file = 'ATR_training.xlsx'\n",
    "num_bins = 50\n",
    "\n",
    "#read labels\n",
    "labels_df = pd.read_excel(excel_file)\n",
    "labels = labels_df['label'].values\n",
    "\n",
    "# Extract histo features for all images\n",
    "\n",
    "feature_list = []\n",
    "file_list = sorted(os.listdir(input_dir))\n",
    "for filename in file_list:\n",
    "    if filename.endswith('.nii.gz'):\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        features = extract_features(input_path, num_bins)\n",
    "        stat_features = extract_stat_features(input_path)\n",
    "        feature_list.append(features)\n",
    "        total_features = features_list + stat_features\n",
    "        \n",
    "#convert list to array\n",
    "X = np.array(total_features)\n",
    "\n",
    "#labels\n",
    "y = np.array(labels)\n",
    "\n",
    "#standarize the features \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#Cross Validation function for each classifier\n",
    "def cross_val(clf,X,y,clf_string, cv=5):\n",
    "    scores = cross_val_score(clf,X, y, cv=cv)\n",
    "    print('Clf: {}\\nAccuracy Mean: {:0.2f}\\nStandard Deviation{:0.2f}'.format(clf_string, scores.mean(), scores.std()))\n",
    "\n",
    "\n",
    "#Testing on multiple models\n",
    "clfs = []\n",
    "svm = SVC(kernel='linear', C=5)\n",
    "clfs.append([svm,'Support Vector Machine'])\n",
    "lr = LogisticRegression(random_state = 0, solver = 'lbfgs',multi_class='multinomial')\n",
    "clfs.append([lr,'Logistic Regression'])\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "clfs.append([ada,'AdaBoost'])\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "clfs.append([knn,'K-Neighbors'])\n",
    "\n",
    "for clf, clf_str in clfs:\n",
    "    cross_val(clf,X_scaled,y,clf_str)\n",
    "\n",
    "#Returns overall Accuracy Score\n",
    "def overall_acc(y_true,y_pred):\n",
    "    return accuracy_score(y_true,y_pred)\n",
    "\n",
    "#Returns the percent detected(#targets detected and #targets)\n",
    "def PD(y_true,y_pred):\n",
    "    return recall_score(y_true,y_pred)\n",
    "\n",
    "#Returns the percent of false alarms(#false alarms and #non-targets)\n",
    "def PFA(y_true,y_pred):\n",
    "    return 1 - accuracy_score(1-y_true,1-y_pred)\n",
    "\n",
    "def results(X,y,clf):\n",
    "    kf = KFold(n_splits=5)\n",
    "    per_det_0 = []\n",
    "    per_det_1 = []\n",
    "    per_det_2 = []\n",
    "    per_det_3 = []\n",
    "    per_false_alarm = []\n",
    "    acc = []\n",
    "    \n",
    "    for train_i, test_i in kf.split(X):\n",
    "        X_train, X_test = X[train_i],X[test_i]\n",
    "        y_train, y_test = y[train_i], y[test_i]\n",
    "        \n",
    "        predict = clf.fit(X_train, y_train != 0).predict(X_test)\n",
    "        \n",
    "        acc.append(overall_acc(y_test != 0, predict))\n",
    "        per_det_0.append(PD(y_test != 0),predict)\n",
    "        per_det_1.append(PD(y_test == 1),predict)\n",
    "        per_det_2.append(PD(y_test == 2),predict)\n",
    "        per_det_3.append(PD(y_test == 3),predict)\n",
    "        per_false_alarm.append(PFA(y_test != 0, predict))\n",
    "        \n",
    "    print('Accuracy: ', np.mean(acc))\n",
    "    print('Percent Detected: ', np.mean(per_det_0))\n",
    "    print('Percent False Alarm: ', np.mean(per_false_alarm))\n",
    "    print('Percent Saline Detected: ', np.mean(per_det_1))\n",
    "    print('Percent Rubber Detected: ', np.mean(per_det_2))\n",
    "    print('Percent Clay Detected: ', np.mean(per_det_3))\n",
    "\n",
    "for clf, clf_str in clfs:\n",
    "    cross_val(clf,X_scaled,y,clf_str)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
